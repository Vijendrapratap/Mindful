diff --git a/backend/server.py b/backend/server.py
index 011f0cb..26cc7b1 100644
--- a/backend/server.py
+++ b/backend/server.py
@@ -209,15 +209,153 @@ async def update_streak(date_str: str):
     
     return await get_or_create_profile()
 
+async def retrieve_knowledge_context(profile_id: str, user_message: str) -> str:
+    """Retrieve relevant context from knowledge graph based on user message"""
+    try:
+        # Get recent nodes and edges for this profile
+        recent_nodes = await db.knowledge_nodes.find(
+            {'profileId': profile_id}
+        ).sort('lastMentioned', -1).limit(20).to_list(20)
+        
+        recent_edges = await db.knowledge_edges.find(
+            {'profileId': profile_id}
+        ).sort('lastUpdated', -1).limit(15).to_list(15)
+        
+        if not recent_nodes:
+            return "No previous context available."
+        
+        # Build context string
+        context_parts = []
+        
+        # Add key entities
+        entities = [node for node in recent_nodes if node['mentionCount'] > 1][:10]
+        if entities:
+            entity_names = [f"{node['entityName']} ({node['entityType']})" for node in entities]
+            context_parts.append(f"Key people/things mentioned: {', '.join(entity_names)}")
+        
+        # Add recent relationships
+        if recent_edges:
+            relationships = []
+            for edge in recent_edges[:5]:
+                source_node = next((n for n in recent_nodes if str(n['_id']) == edge['sourceNodeId']), None)
+                target_node = next((n for n in recent_nodes if str(n['_id']) == edge['targetNodeId']), None)
+                if source_node and target_node:
+                    relationships.append(f"{source_node['entityName']} {edge['relationshipType']} {target_node['entityName']}")
+            
+            if relationships:
+                context_parts.append(f"Recent connections: {'; '.join(relationships)}")
+        
+        return " | ".join(context_parts) if context_parts else "No specific context available."
+        
+    except Exception as e:
+        logger.error(f"Error retrieving knowledge context: {str(e)}")
+        return "Context retrieval unavailable."
+
+async def extract_knowledge_from_message(profile_id: str, conversation_id: str, user_message: str, ai_response: str):
+    """Extract knowledge entities and relationships from conversation"""
+    try:
+        # Simple extraction logic - in production, you'd use NLP/LLM for this
+        # For now, we'll do basic keyword extraction
+        
+        # Extract potential entities (simplified approach)
+        import re
+        
+        # Look for people (capitalized names)
+        people = re.findall(r'\b[A-Z][a-z]+(?:\s+[A-Z][a-z]+)*\b', user_message)
+        people = [p for p in people if len(p.split()) <= 3 and p not in ['I', 'My', 'The', 'This', 'That']]
+        
+        # Look for emotions
+        emotions = ['happy', 'sad', 'angry', 'excited', 'anxious', 'calm', 'frustrated', 'grateful', 'worried', 'content']
+        found_emotions = [emotion for emotion in emotions if emotion in user_message.lower()]
+        
+        # Look for activities (basic patterns)
+        activity_patterns = [r'went to (\w+)', r'had (\w+)', r'did (\w+)', r'played (\w+)', r'watched (\w+)']
+        activities = []
+        for pattern in activity_patterns:
+            matches = re.findall(pattern, user_message.lower())
+            activities.extend(matches)
+        
+        # Store extracted entities
+        extracted_nodes = []
+        extracted_edges = []
+        
+        # Store people
+        for person in people[:3]:  # Limit to avoid spam
+            node = await store_or_update_node(profile_id, 'Person', person)
+            if node:
+                extracted_nodes.append(str(node['_id']))
+        
+        # Store emotions
+        for emotion in found_emotions[:2]:
+            node = await store_or_update_node(profile_id, 'Emotion', emotion)
+            if node:
+                extracted_nodes.append(str(node['_id']))
+        
+        # Store activities
+        for activity in activities[:2]:
+            node = await store_or_update_node(profile_id, 'Activity', activity)
+            if node:
+                extracted_nodes.append(str(node['_id']))
+        
+        # Log the extraction
+        extraction_log = ExtractionLog(
+            profileId=profile_id,
+            conversationId=conversation_id,
+            messageContent=user_message,
+            extractedNodes=extracted_nodes,
+            extractedEdges=extracted_edges
+        )
+        await db.extraction_logs.insert_one(extraction_log.dict(exclude={'id'}))
+        
+    except Exception as e:
+        logger.error(f"Error extracting knowledge: {str(e)}")
+
+async def store_or_update_node(profile_id: str, entity_type: str, entity_name: str):
+    """Store or update a knowledge node"""
+    try:
+        # Check if node already exists
+        existing = await db.knowledge_nodes.find_one({
+            'profileId': profile_id,
+            'entityType': entity_type,
+            'entityName': entity_name
+        })
+        
+        if existing:
+            # Update existing node
+            await db.knowledge_nodes.update_one(
+                {'_id': existing['_id']},
+                {
+                    '$set': {'lastMentioned': datetime.utcnow()},
+                    '$inc': {'mentionCount': 1}
+                }
+            )
+            return existing
+        else:
+            # Create new node
+            node = KnowledgeNode(
+                profileId=profile_id,
+                entityType=entity_type,
+                entityName=entity_name
+            )
+            result = await db.knowledge_nodes.insert_one(node.dict(exclude={'id'}))
+            return await db.knowledge_nodes.find_one({'_id': result.inserted_id})
+            
+    except Exception as e:
+        logger.error(f"Error storing knowledge node: {str(e)}")
+        return None
+
 async def get_ai_response(conversation_id: str, user_message: str, conversation_type: str):
     """Get AI response using Claude via emergentintegrations"""
     try:
-        # Get conversation history
-        conversation = await db.conversations.find_one({'_id': ObjectId(conversation_id)})
+        # Get profile for knowledge graph context
+        profile = await get_or_create_profile()
+        
+        # Retrieve relevant context from knowledge graph
+        context = await retrieve_knowledge_context(profile['id'], user_message)
         
         # Create system message based on type
         if conversation_type == "journal":
-            system_message = """You are MindfulMe, a warm and compassionate journaling companion. 
+            system_message = f"""You are MindfulMe, a warm and compassionate journaling companion. 
             Your role is to help users reflect on their day through natural conversation.
             
             Guidelines:
@@ -229,12 +367,17 @@ async def get_ai_response(conversation_id: str, user_message: str, conversation_
             - Help users process their day, not solve their problems
             - Use conversational language, like a caring friend
             
+            Context about the user (from previous conversations):
+            {context}
+            
+            Use this context naturally when relevant, but don't force it into every response.
+            
             Example responses:
             - "That sounds like it was challenging. What made it particularly difficult for you?"
             - "I hear excitement in what you're sharing! What part of that experience felt most meaningful?"
-            - "It seems like that really affected you. How are you feeling about it now?"""
+            - "It seems like that really affected you. How are you feeling about it now?\""""
         else:  # chat
-            system_message = """You are MindfulMe, a supportive mental wellness companion and friend.
+            system_message = f"""You are MindfulMe, a supportive mental wellness companion and friend.
             Your role is to provide a safe, non-judgmental space for users to talk about their thoughts and feelings.
             
             Guidelines:
@@ -247,6 +390,12 @@ async def get_ai_response(conversation_id: str, user_message: str, conversation_
             - Show genuine interest in understanding their perspective
             - Recognize when to offer comfort vs. when to ask deeper questions
             
+            Context about the user (from previous conversations):
+            {context}
+            
+            Use this context to show you remember them and care about their journey.
+            Reference past events naturally when appropriate.
+            
             Remember: You're here to listen, understand, and support - not to fix or diagnose."""
         
         # Initialize AI chat
@@ -262,6 +411,14 @@ async def get_ai_response(conversation_id: str, user_message: str, conversation_
         # Get response
         response = await chat.send_message(message)
         
+        # Extract knowledge in background (don't wait for it)
+        asyncio.create_task(extract_knowledge_from_message(
+            profile['id'], 
+            conversation_id, 
+            user_message, 
+            response
+        ))
+        
         return response
         
     except Exception as e:
@@ -517,6 +674,74 @@ async def get_mood_stats(days: int = 30):
         "moodDistribution": mood_counts
     }
 
+# Knowledge Graph endpoints
+@api_router.get("/knowledge/nodes")
+async def get_knowledge_nodes(limit: int = 50):
+    """Get knowledge nodes for the user"""
+    profile = await get_or_create_profile()
+    nodes = await db.knowledge_nodes.find(
+        {'profileId': profile['id']}
+    ).sort('lastMentioned', -1).limit(limit).to_list(limit)
+    return [serialize_doc(node) for node in nodes]
+
+@api_router.get("/knowledge/edges")
+async def get_knowledge_edges(limit: int = 50):
+    """Get knowledge edges for the user"""
+    profile = await get_or_create_profile()
+    edges = await db.knowledge_edges.find(
+        {'profileId': profile['id']}
+    ).sort('lastUpdated', -1).limit(limit).to_list(limit)
+    return [serialize_doc(edge) for edge in edges]
+
+@api_router.get("/knowledge/graph")
+async def get_knowledge_graph():
+    """Get complete knowledge graph for visualization"""
+    profile = await get_or_create_profile()
+    
+    # Get nodes and edges
+    nodes = await db.knowledge_nodes.find(
+        {'profileId': profile['id']}
+    ).sort('mentionCount', -1).limit(100).to_list(100)
+    
+    edges = await db.knowledge_edges.find(
+        {'profileId': profile['id']}
+    ).limit(100).to_list(100)
+    
+    return {
+        "nodes": [serialize_doc(node) for node in nodes],
+        "edges": [serialize_doc(edge) for edge in edges]
+    }
+
+@api_router.get("/knowledge/stats")
+async def get_knowledge_stats():
+    """Get knowledge graph statistics"""
+    profile = await get_or_create_profile()
+    
+    # Count nodes by type
+    node_pipeline = [
+        {"$match": {"profileId": profile['id']}},
+        {"$group": {"_id": "$entityType", "count": {"$sum": 1}}}
+    ]
+    node_stats = await db.knowledge_nodes.aggregate(node_pipeline).to_list(100)
+    
+    # Count edges by type
+    edge_pipeline = [
+        {"$match": {"profileId": profile['id']}},
+        {"$group": {"_id": "$relationshipType", "count": {"$sum": 1}}}
+    ]
+    edge_stats = await db.knowledge_edges.aggregate(edge_pipeline).to_list(100)
+    
+    # Total counts
+    total_nodes = await db.knowledge_nodes.count_documents({'profileId': profile['id']})
+    total_edges = await db.knowledge_edges.count_documents({'profileId': profile['id']})
+    
+    return {
+        "totalNodes": total_nodes,
+        "totalEdges": total_edges,
+        "nodesByType": {stat['_id']: stat['count'] for stat in node_stats},
+        "edgesByType": {stat['_id']: stat['count'] for stat in edge_stats}
+    }
+
 # Include router
 app.include_router(api_router)
 
diff --git a/model.patch b/model.patch
index 93ed673..197bc17 100644
--- a/model.patch
+++ b/model.patch
@@ -1,12 +0,0 @@
-diff --git a/backend/server.py b/backend/server.py
-index eb6dafa..96e524d 100644
---- a/backend/server.py
-+++ b/backend/server.py
-@@ -132,6 +132,7 @@ async def update_streak(date_str: str):
-     if not profile.get('lastJournalDate'):
-         # First journal entry
-         new_streak = 1
-+        days_diff = 1  # First entry counts as 1 day
-     else:
-         last_date = datetime.strptime(profile['lastJournalDate'], '%Y-%m-%d').date()
-         days_diff = (today - last_date).days
